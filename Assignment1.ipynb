{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Implementing a tokenizer\n",
    "Implement a basic whitespace tokenizer in Python from scratch without the use of any NLP\n",
    "libraries. This tokenizer should drop whitespaces and create tokens for the following cases:\n",
    "\n",
    "(a) End-of-sentence (EOS) symbols, brackets and separators\n",
    "\n",
    "(b) Abbreviations - Assume those are only one of the following: Ph.D., Dr., M.Sc.\n",
    "\n",
    "(c) Special characters as in prices separated (i.e. $45.55)\n",
    "\n",
    "(d) Dates - Assume that they follow the format dd/mm/yy (i.e. 01/02/06)\n",
    "\n",
    "(e) URLs - Assume that they follow the format:\n",
    "http[s]://[...], (i.e. https://www.stanford.edu)\n",
    "\n",
    "(f) Hashtags separated (i.e. #nlproc)\n",
    "\n",
    "(g) Email addresses - Assume that they follow the format:\n",
    "name@domain.xyz (i.e. someOne@brown.edu)\n",
    "\n",
    "Apply your code on the test example below, which should yield the specified tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"He has a M.Sc. in Math and she has a Ph.D. in NLP. A session costs 45.55$ or $50.00. As of 01/02/06, please email X/Y at someone@brown.edu or visit http://www.stanford.edu and if link does not work try https://www.stanford.edu instead. #test#test2#nlproc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaTokenizer():\n",
    "    def __init__(self):\n",
    "        self.abbreviations = [\"Ph.D.\", \"Dr.\", \"M.Sc.\"]\n",
    "        self.abbr_pattern = r'Ph\\.D\\.|Dr\\.|M\\.Sc\\.'\n",
    "        self.separators = [\".\", \",\", \"/\", \"(\", \")\"]\n",
    "        self.separators_pattern = r'[.,/()!]'\n",
    "        self.date_pattern = r'\\b\\d{2}/\\d{2}/\\d{2,4}\\b'\n",
    "        self.prices_pattern = r'\\$\\d+(?:\\.\\d{1,2})?|\\d+(?:\\.\\d{1,2})?\\$'\n",
    "        self.urls_pattern = r'https?://(?:www\\.)?[a-zA-Z0-9\\-]+\\.[a-zA-Z]{2,}'\n",
    "        self.emails_pattern = r'[a-zA-Z0-9]+@[a-zA-Z0-9]+\\.[a-zA-Z]+'\n",
    "        self.hashtags_pattern = r'\\#[a-zA-Z0-9]+'\n",
    "        self.words = r'[a-zA-Z0-9]+'\n",
    "        self.combined_pattern = f'{self.date_pattern}|{self.abbr_pattern}|{self.prices_pattern}|{self.urls_pattern}|{self.emails_pattern}|{self.hashtags_pattern}|{self.words}|{self.separators_pattern}'\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        #get words from text\n",
    "        tokens = re.findall(self.combined_pattern, text)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = VanillaTokenizer()\n",
    "tokens = tokenizer.tokenize(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'has',\n",
       " 'a',\n",
       " 'M.Sc.',\n",
       " 'in',\n",
       " 'Math',\n",
       " 'and',\n",
       " 'she',\n",
       " 'has',\n",
       " 'a',\n",
       " 'Ph.D.',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'A',\n",
       " 'session',\n",
       " 'costs',\n",
       " '45.55$',\n",
       " 'or',\n",
       " '$50.00',\n",
       " '.',\n",
       " 'As',\n",
       " 'of',\n",
       " '01/02/06',\n",
       " ',',\n",
       " 'please',\n",
       " 'email',\n",
       " 'X',\n",
       " '/',\n",
       " 'Y',\n",
       " 'at',\n",
       " 'someone@brown.edu',\n",
       " 'or',\n",
       " 'visit',\n",
       " 'http://www.stanford.edu',\n",
       " 'and',\n",
       " 'if',\n",
       " 'link',\n",
       " 'does',\n",
       " 'not',\n",
       " 'work',\n",
       " 'try',\n",
       " 'https://www.stanford.edu',\n",
       " 'instead',\n",
       " '.',\n",
       " '#test',\n",
       " '#test2',\n",
       " '#nlproc']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
